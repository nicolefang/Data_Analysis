---
title: "Pricing Test"
output:
  html_document:
    df_print: paged
    toc: true
    toc_depth: 2
---

# 0. Background 
Company XYZ sells a software for $\$39$. Since revenue has been flat for some time, the VP of Product has decided to run a test increasing the price. She hopes that this would increase revenue. In the experiment, 66% of the users have seen the old price ($\$39$), while a random sample of 33% users a higher price ($\$59$).

The test has been running for some time and the VP of Product is interested in understanding how it went and whether it would make sense to increase the price for all the users.Especially he asked you the following questions:
* 1. Should the company sell its software for $\$39$ or $\$59$?
* 2. The VP of Product is interested in having a holistic view into user behavior, especially focusing on actionable insights that might increase conversion rate. What are your main findings looking at the data?

# 1. Set up & load data
```{r}
rm(list = ls())
gc()
directory <- "C:/Users/nicol/OneDrive/Desktop/DSexercise/6_Pricing Test"
setwd(directory)

# library needed
if (!require(tidyverse)) {
  install.packages("tidyverse")
}
library(tidyverse)

if (!require(Hmisc)) {
  install.packages("Hmisc")
}
library(Hmisc)

test_results <- read.csv(paste0(directory, "/test_results.csv"))
user_table <- read.csv(paste0(directory, "/user_table.csv"))
```


# 2. Check data quality and clean data
```{r}
head(test_results) # Look at the first few rows
head(user_table)

length(unique(test_results$user_id))
length(unique(user_table$user_id))

data <- test_results %>% left_join(user_table, by = "user_id")
describe(data)

data$city <- ifelse(is.na(data$city), "Unknown", data$city)
data$country <- ifelse(is.na(data$country), "Unknown", data$country)
```

There is more users in the test table than the user table, so I will do a left join to make sure no data is lost. We don't have information about why these user are missing. It might because of self-selection. So I will make missing info a category.

```{r}
data %>%
  group_by(test, price) %>%
  count()
data <- data %>% filter((test == 0 & price == 39) | (test == 1 & price == 59))
```

It seems that there are some problems with the data. There are a small amount of users who are labeled as test=0 but actually see price $\$59$. There are a small amount of users who are labeled as test=1 but actually see price $\$39$. Fortunately, they are only a very small portion of the whole data set. The first step is to remove these rows. If it is in the real work, I will talk to engineers to understand the bug.

# 3. Sanity check: Is test and control group splitted randomly?
```{r}
data$test <- as.factor(data$test)

data %>%
  group_by(test) %>%
  summarise(num = n(), .groups="drop") %>%
  mutate(
    total = sum(num),
    pct = num / total
  )
```

Given each user is randomly assigned to the test with probability of 33.3%. The 5% confidence interval is [0.3284, 0.3316]. There were 36% of users assigned to the test group. The test and control split seems not to be random. First, I will check day-by-day, see if any particular day cause the problem.

## 1) Date pattern
```{r}
data %>%
  group_by(test, month = substr(timestamp, 6, 7), day = substr(timestamp, 9, 10)) %>%
  summarise(num = n(), .groups = "drop") %>%
  group_by(month, day) %>%
  mutate(
    total = sum(num),
    pct = num / total
  ) %>%
  select(test, month, day, pct) %>%
  mutate(day = as.integer(day)) %>%
  ggplot(aes(x = day, y = pct, group = test)) +
  geom_line(aes(color = test)) +
  scale_color_manual(values = c("goldenrod1", "slateblue1")) +
  scale_x_continuous(
    breaks = c(0, 5, 10, 15, 20, 25, 30), 
    labels = c(0, 5, 10, 15, 20, 25, 30)
  ) + 
  theme_bw() +
  theme(panel.border = element_blank(),
    axis.ticks = element_blank(),
    panel.grid.major.y = element_line(color = "grey70"),
    panel.grid.minor.y = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  ) +  labs(
    title = "Daily User Split",
    subtitle = "Control vs Test group",
    x = "Day", y = "Percentage"
  )+
  facet_wrap(~month)

```

There is no clear pattern in day-to-day trend. Next I will slice the data by source, device, and operative system, to check if any particular slice causes the problem.

## 2) Source
```{r}
data %>%
  group_by(test, source) %>%
  summarise(num = n(), .groups = "drop") %>%
  group_by(source) %>%
  mutate(
    total = sum(num),
    pct = num / total
  ) %>%
  select(test, source, pct) %>%
  spread(key = test, value = pct)

data %>%
  group_by(test, source) %>%
  summarise(num = n(), .groups = "drop") %>%
  mutate(
    total = sum(num),
    pct = num / total
  ) %>%
  ggplot(aes(x = reorder(source, pct), y = pct, group = test)) +
  geom_bar(stat = "identity", position = "dodge", aes(fill = test)) +
  scale_fill_manual(values = c("goldenrod1", "slateblue1")) +
  theme_bw() +
  theme(panel.border = element_blank(),
    axis.ticks = element_blank(),
    panel.grid.major.y = element_line(color = "grey70"),
    panel.grid.minor.y = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  ) +
  labs(
    title = "Source Distribution",
    subtitle = "Control vs Test group",
    x = "Sources", y = "Percentage"
  ) +
  coord_flip()

```

## 3) Device 
```{r}
data %>%
  group_by(test, device) %>%
  summarise(num = n(), .groups = "drop") %>%
  group_by(device) %>%
  mutate(
    total = sum(num),
    pct = num / total
  ) %>%
  select(test, device, pct) %>%
  spread(key = test, value = pct)

data %>%
  group_by(test, device) %>%
  summarise(num = n(), .groups = "drop") %>%
  mutate(
    total = sum(num),
    pct = num / total
  ) %>%
  ggplot(aes(x = reorder(device, pct), y = pct, group = test)) +
  geom_bar(stat = "identity", position = "dodge", aes(fill = test)) +
  scale_fill_manual(values = c("goldenrod1", "slateblue1")) +
  theme_bw() +
  theme( # legend.position = "bottom",
    panel.border = element_blank(),
    axis.ticks = element_blank(),
    panel.grid.major.y = element_line(color = "grey70"),
    panel.grid.minor.y = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  ) +
  labs(
    title = "Device Distribution",
    subtitle = "Control vs Test group",
    x = "Sources", y = "Percentage"
  )

```

## 4) OS
```{r}
data %>%
  group_by(test, operative_system) %>%
  summarise(num = n(), .groups = "drop") %>%
  group_by(operative_system) %>%
  mutate(
    total = sum(num),
    pct = num / total
  ) %>%
  select(test, operative_system, pct) %>%
  spread(key = test, value = pct)


data %>%
  group_by(test, operative_system) %>%
  summarise(num = n(), .groups = "drop") %>%
  mutate(
    total = sum(num),
    pct = num / total
  ) %>%
  ggplot(aes(x = reorder(operative_system, desc(pct)), y = pct, group = test)) +
  geom_bar(stat = "identity", position = "dodge", aes(fill = test)) +
  scale_fill_manual(values = c("goldenrod1", "slateblue1")) +
  theme_bw() +
  theme( # legend.position = "bottom",
    panel.border = element_blank(),
    axis.ticks = element_blank(),
    panel.grid.major.y = element_line(color = "grey70"),
    panel.grid.minor.y = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  ) +
  labs(
    title = "Operative System Distribution",
    subtitle = "Control vs Test group",
    x = "Sources", y = "Percentage"
  )

```

Run Chi-Square test to confirm if any factor impacted the splitting between test/control group.

```{r}
chisq.test(data$source, data$test)
chisq.test(data$device, data$test)
chisq.test(data$operative_system, data$test)
```

From the result above, we know that the splitting between test/control groups is not random. OS and device have great impact on the split. Especially, 47% of Linux users are assigned to the test group, way above 33%. I will talk to engineers, see if the experiment is set up correctly. 

We need to keep this in mind in the following analysis.

# 4. Question 1: Should the company sell its software for \$39 or \$59?
```{r}
data$revenue <- data$price * data$converted

data %>%
  group_by(test) %>%
  summarise(
    num = n(),
    convert_rate = mean(converted),
    avg_revenue = mean(revenue),
    .groups = "drop"
  )
```

We will use a t-test to determine whether the test group average revenue is higher than the control group.
H0: test group's average revenue is the same as the control group's.
Ha: test group's average revenue is higher than the control group's.
```{r}
t.test(data$revenue[data$test == 1], data$revenue[data$test == 0], alternative = "greater")
```

With p-value less than 0.05 significance level, I will reject the H0 hypothesis, and conclude that the test group average revenue is higher than the control group's.

However, as the OS and device distribution are not the same between the two groups, price is not the only difference between test and control groups. The experiment design fails, I cannot determine whether to sell $\$59$ or $\$39$. I would talk to engineers to find out the reasons for non-random split in OS and device, especially the Linux users. Then rerun the experiment, and repeat the t-test above to draw the conclusion.


# 5. Question 2: Holistic view of user behavior and action to increase conversion rate
## 1) How does the source affect the conversion
```{r}
data %>%
  group_by(source) %>%
  summarise(convert_rate = mean(converted), .groups = "drop") %>%
  ggplot() +
  geom_bar(aes(x = reorder(source, convert_rate), y = convert_rate), fill = "slateblue1", stat = "identity") +
  geom_hline(
    yintercept = 0.02, linetype = 2,
    color = "green"
  ) +
  annotate("text",
    label = "High conversion", color = "dark green",
    x = 5, y = 0.02,
    hjust = -0.1
  ) +
  coord_flip() +
  theme_bw() +
  labs(
    title = "Friend referral has the highest conversion rate",
    x = "Sources", y = "Conversion Rate"
  )
```

* Friend referral has the highest conversion, which indicates the power of word of mouth. We could do a referral discount or referral bonus to encourage it. 
* Google and Facebook also perform well. We can inform the marketing department, and see if they did something different for these two channels.
* Seo Bing also do well in conversion rate; however given less than 1% of traffic comes from the seo Bing, there is no actionable insights.

## 2) How does the pricing affect the conversion
```{r}
data %>%
  group_by(price) %>%
  summarise(convert_rate = mean(converted), .groups = "drop") %>%
  ggplot() +
  geom_bar(aes(x = reorder(price, convert_rate), y = convert_rate), fill = "slateblue2", stat = "identity") +
  xlab("Price") +
  theme_bw() +
  labs(
    title = "39 dollar group has conversion rate about 40 bps higher",
    x = "Price", y = "Conversion Rate"
  )
```

## 3) How does the OS affect the conversion
```{r}
data %>%
  group_by(operative_system) %>%
  summarise(convert_rate = mean(converted), .groups = "drop") %>%
  ggplot() +
  geom_bar(aes(x = reorder(operative_system, convert_rate), y = convert_rate), fill = "slateblue2", stat = "identity") +
  geom_hline(
    yintercept = 0.02, linetype = 2,
    color = "green"
  ) +
  annotate("text",
    label = "High conversion", color = "dark green",
    x = 5, y = 0.02,
    hjust = 2, vjust = -0.5
  ) +
  xlab("OS") +
  theme_bw()

```

Apple users have high conversion rate, while linux users have the lowest conversion.

## 4) Actionable insights
* Friend referral, apple user and low price are the most important factors in improving conversion rate.
* Increasing the price will hurt the conversion rate, so we should work with marketing teams to compensate on the other two factors, for example, launching special marketing program targeting Apple users (MAC or iOS users), or offering referral bonus/discount to users.
* Linux users don't like our software as much as users on other OS. We can work with engineering teams to find out the reason. For example, is there any incompatibility or bug on Linux?
